{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "                \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(12.7,10.27)})\n",
    "\n",
    "# notebook settings\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTCGA(disease):\n",
    "    path = \"/srv/nas/mk2/projects/pan-cancer/TCGA_CCLE_GCP/TCGA/TCGA_{}_counts.tsv.gz\"\n",
    "    files = [path.format(d) for d in disease]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGCP(files):\n",
    "    \"\"\"\n",
    "    Paths to count matrices.\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    for f in files:\n",
    "        key = os.path.basename(f).split(\"_\")[1]\n",
    "        data = pd.read_csv(f, sep='\\t', index_col=0)\n",
    "        meta = pd.DataFrame([row[:-1] for row in data.index.str.split(\"|\")],\n",
    "                            columns=['ENST', 'ENSG', 'OTTHUMG', 'OTTHUMT', 'GENE-NUM', 'GENE', 'NUM', 'TYPE'])\n",
    "        data.index = meta['GENE']\n",
    "        data_dict[key] = data.T\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameTCGA(data_dict, mapper):\n",
    "    for key in data_dict.keys():\n",
    "        data_dict[key] = data_dict[key].rename(mapper)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uq_norm(df, q=0.75):\n",
    "    \"\"\"\n",
    "    Upper quartile normalization of GEX for samples.\n",
    "    \"\"\"\n",
    "    quantiles = df.quantile(q=q, axis=1)\n",
    "    norm = df.divide(quantiles, axis=0)\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/srv/nas/mk2/projects/pan-cancer/TCGA_CCLE_GCP\"\n",
    "disease = ['BRCA', 'LUAD', 'KIRC', 'THCA', 'PRAD', 'SKCM']\n",
    "\n",
    "tcga_files = getTCGA(disease)\n",
    "tcga_meta = pd.read_csv(os.path.join(base, \"TCGA/TCGA_GDC_ID_MAP.tsv\"), sep=\"\\t\")\n",
    "tcga_raw = readGCP(tcga_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename samples to reflect canonical IDs\n",
    "tcga_raw = renameTCGA(tcga_raw, mapper=dict(zip(tcga_meta['CGHubAnalysisID'], tcga_meta['Sample ID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine samples\n",
    "tcga_raw = pd.concat(tcga_raw.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper quartile normalization\n",
    "tcga_raw = uq_norm(tcga_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log norm\n",
    "tcga = tcga_raw.transform(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4078, 199169)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample\n",
    "tcga = tcga.sample(n=18000, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CGHubAnalysisID</th>\n",
       "      <th>AliquotBarcode</th>\n",
       "      <th>Aliquot_id</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Case ID</th>\n",
       "      <th>Sample ID</th>\n",
       "      <th>Sample Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>d7f11b34-6b38-4a7a-80b1-fae9b7243caf</td>\n",
       "      <td>TCGA-A7-A26F-01B-04R-A22O-07</td>\n",
       "      <td>1B907925-B33C-4E4A-96E0-65F15B4712B9</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>TCGA-A7-A26F</td>\n",
       "      <td>TCGA-A7-A26F-01B</td>\n",
       "      <td>Primary Tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>822d3bb2-b845-4073-a5fb-7ecf9e5c10a1</td>\n",
       "      <td>TCGA-A7-A26F-01B-04R-A22O-07</td>\n",
       "      <td>1B907925-B33C-4E4A-96E0-65F15B4712B9</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>TCGA-A7-A26F</td>\n",
       "      <td>TCGA-A7-A26F-01B</td>\n",
       "      <td>Primary Tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>0c30f5b1-5ed5-48d1-b8df-df4611761dd3</td>\n",
       "      <td>TCGA-A7-A26F-01B-04R-A22O-07</td>\n",
       "      <td>1B907925-B33C-4E4A-96E0-65F15B4712B9</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>TCGA-A7-A26F</td>\n",
       "      <td>TCGA-A7-A26F-01B</td>\n",
       "      <td>Primary Tumor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           CGHubAnalysisID                AliquotBarcode  \\\n",
       "7264  d7f11b34-6b38-4a7a-80b1-fae9b7243caf  TCGA-A7-A26F-01B-04R-A22O-07   \n",
       "7265  822d3bb2-b845-4073-a5fb-7ecf9e5c10a1  TCGA-A7-A26F-01B-04R-A22O-07   \n",
       "7266  0c30f5b1-5ed5-48d1-b8df-df4611761dd3  TCGA-A7-A26F-01B-04R-A22O-07   \n",
       "\n",
       "                                Aliquot_id Disease       Case ID  \\\n",
       "7264  1B907925-B33C-4E4A-96E0-65F15B4712B9    BRCA  TCGA-A7-A26F   \n",
       "7265  1B907925-B33C-4E4A-96E0-65F15B4712B9    BRCA  TCGA-A7-A26F   \n",
       "7266  1B907925-B33C-4E4A-96E0-65F15B4712B9    BRCA  TCGA-A7-A26F   \n",
       "\n",
       "             Sample ID    Sample Type  \n",
       "7264  TCGA-A7-A26F-01B  Primary Tumor  \n",
       "7265  TCGA-A7-A26F-01B  Primary Tumor  \n",
       "7266  TCGA-A7-A26F-01B  Primary Tumor  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcga_meta[tcga_meta['Sample ID'] == 'TCGA-A7-A26F-01B']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict \n",
    "hierarchy = OrderedDict({'Disease':['BRCA'],#, 'LUAD', 'KIRC', 'THCA', 'PRAD', 'SKCM'],\n",
    "                         'Sample Type':['Primary Tumor', 'Solid Tissue Normal', 'Metastatic']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment():\n",
    "    \"\"\"\n",
    "    Defines an experimental class hierarchy object.\n",
    "    \"\"\"\n",
    "    def __init__(self, meta_data, hierarchy, cases, min_samples):\n",
    "        self.hierarchy = hierarchy\n",
    "        self.meta_data = self.categorize(meta_data, self.hierarchy, min_samples)\n",
    "        self.cases = self.meta_data[cases].unique()\n",
    "        self.labels = self.meta_data['meta'].cat.codes.values.astype('int')\n",
    "        self.labels_dict = {key:val for key,val in enumerate(self.meta_data['meta'].cat.categories.values)}\n",
    "        \n",
    "    def categorize(self, meta_data, hierarchy, min_samples):\n",
    "        assert isinstance(hierarchy, OrderedDict), \"Argument of wrong type.\"\n",
    "        # downsample data\n",
    "        for key,val in hierarchy.items():\n",
    "            meta_data = meta_data[meta_data[key].isin(val)]\n",
    "        # unique meta classes\n",
    "        meta_data['meta'] = meta_data[list(hierarchy.keys())].apply(lambda row: ':'.join(row.values.astype(str)), axis=1)\n",
    "        # filter meta classes\n",
    "        counts = meta_data['meta'].value_counts()\n",
    "        keep = counts[counts > min_samples].index\n",
    "        meta_data = meta_data[meta_data['meta'].isin(keep)]\n",
    "        # generate class categories\n",
    "        meta_data['meta'] = meta_data['meta'].astype('category')\n",
    "        return meta_data\n",
    "    \n",
    "    def holdout(self, holdout):\n",
    "        self.holdout = holdout\n",
    "        self.holdout_samples = self.meta_data[self.meta_data['meta'].isin(holdout)]\n",
    "        self.meta_data = self.meta_data[~self.meta_data['meta'].isin(holdout)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dutils import train_test_split_case\n",
    "exp = Experiment(meta_data=tcga_meta,\n",
    "                 hierarchy=hierarchy,\n",
    "                 cases='Case ID',\n",
    "                 min_samples=20)\n",
    "exp.holdout(holdout=['SKCM:Metastatic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRCA:Primary Tumor          1119\n",
       "BRCA:Solid Tissue Normal     114\n",
       "Name: meta, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "BRCA:Solid Tissue Normal    0\n",
       "BRCA:Primary Tumor          0\n",
       "Name: meta, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.meta_data['meta'].value_counts()\n",
    "exp.holdout_samples['meta'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRCA:Primary Tumor          0.804290\n",
       "BRCA:Solid Tissue Normal    0.807018\n",
       "Name: meta, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "BRCA:Primary Tumor          0.195710\n",
       "BRCA:Solid Tissue Normal    0.192982\n",
       "Name: meta, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Train / Test sample split\n",
    "target = 'meta'\n",
    "\n",
    "train, test = train_test_split_case(exp.meta_data, cases='Case ID')\n",
    "# stratification is not quite perfect but close\n",
    "# in order to preserve matched samples for each case together\n",
    "# in train or test set\n",
    "case_counts = exp.meta_data[target].value_counts()\n",
    "train[target].value_counts()[case_counts.index.to_numpy()] / case_counts\n",
    "test[target].value_counts()[case_counts.index.to_numpy()] / case_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_data = tcga[tcga.index.isin(train['Sample ID'])].astype(np.float16)\n",
    "test_data = tcga[tcga.index.isin(test['Sample ID'])].astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "#torch.manual_seed(123)\n",
    "\n",
    "from trainer import fit\n",
    "import visualization as vis\n",
    "import numpy as np\n",
    "cuda = torch.cuda.is_available()\n",
    "print(\"Cuda is available: {}\".format(cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SiameseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Train: For each sample creates randomly a positive or a negative pair\n",
    "    Test: Creates fixed pairs for testing\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, experiment, data, train=False):\n",
    "        self.train = train\n",
    "        self.labels = experiment.meta_data[experiment\n",
    "                                           .meta_data['Sample ID']\n",
    "                                           .isin(data.index)]['meta'].cat.codes.values.astype('int')\n",
    "        assert len(data) == len(self.labels)\n",
    "\n",
    "        if self.train:\n",
    "            self.train_labels = self.labels\n",
    "            self.train_data = torch.from_numpy(data.values).float()\n",
    "            self.labels_set = set(self.train_labels)\n",
    "            self.label_to_indices = {label: np.where(self.train_labels == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "        else:\n",
    "            # generate fixed pairs for testing\n",
    "            self.test_labels = self.labels\n",
    "            self.test_data = torch.from_numpy(data.values).float()\n",
    "            self.labels_set = set(self.test_labels)\n",
    "            self.label_to_indices = {label: np.where(self.test_labels == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "\n",
    "            random_state = np.random.RandomState(29)\n",
    "\n",
    "            positive_pairs = [[i,\n",
    "                               random_state.choice(self.label_to_indices[self.test_labels[i].item()]),\n",
    "                               1]\n",
    "                              for i in range(0, len(self.test_data), 2)]\n",
    "\n",
    "            negative_pairs = [[i,\n",
    "                               random_state.choice(self.label_to_indices[\n",
    "                                                       np.random.choice(\n",
    "                                                           list(self.labels_set - set([self.test_labels[i].item()]))\n",
    "                                                       )\n",
    "                                                   ]),\n",
    "                               0]\n",
    "                              for i in range(1, len(self.test_data), 2)]\n",
    "            self.test_pairs = positive_pairs + negative_pairs\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            target = np.random.randint(0, 2)\n",
    "            img1, label1 = self.train_data[index], self.train_labels[index].item()\n",
    "            if target == 1:\n",
    "                siamese_index = index\n",
    "                while siamese_index == index:\n",
    "                    siamese_index = np.random.choice(self.label_to_indices[label1])\n",
    "            else:\n",
    "                siamese_label = np.random.choice(list(self.labels_set - set([label1])))\n",
    "                siamese_index = np.random.choice(self.label_to_indices[siamese_label])\n",
    "            img2 = self.train_data[siamese_index]\n",
    "        else:\n",
    "            img1 = self.test_data[self.test_pairs[index][0]]\n",
    "            img2 = self.test_data[self.test_pairs[index][1]]\n",
    "            target = self.test_pairs[index][2]\n",
    "        \n",
    "        return (img1, img2), target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_train_dataset = SiameseDataset(experiment=exp,\n",
    "                                       data=train_data,\n",
    "                                       train=True)\n",
    "siamese_test_dataset = SiameseDataset(experiment=exp,\n",
    "                                       data=test_data,\n",
    "                                       train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseNet(\n",
       "  (embedding_net): EmbeddingNet(\n",
       "    (fc): Sequential(\n",
       "      (linear1): Linear(in_features=199169, out_features=2000, bias=True)\n",
       "      (relu1): PReLU(num_parameters=1)\n",
       "      (linear2): Linear(in_features=2000, out_features=500, bias=True)\n",
       "      (relu2): PReLU(num_parameters=1)\n",
       "      (linear3): Linear(in_features=500, out_features=250, bias=True)\n",
       "      (relu3): PReLU(num_parameters=1)\n",
       "      (linear4): Linear(in_features=250, out_features=100, bias=True)\n",
       "      (relu4): PReLU(num_parameters=1)\n",
       "      (linear5): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (relu5): PReLU(num_parameters=1)\n",
       "      (linear6): Linear(in_features=50, out_features=10, bias=True)\n",
       "      (relu6): PReLU(num_parameters=1)\n",
       "      (linear7): Linear(in_features=10, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "kwargs = {'num_workers': 10, 'pin_memory': True} if cuda else {'num_workers': 10}\n",
    "siamese_train_loader = torch.utils.data.DataLoader(siamese_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "siamese_test_loader = torch.utils.data.DataLoader(siamese_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "# Set up the network and training parameters\n",
    "from tcga_networks import EmbeddingNet, SiameseNet\n",
    "from losses import ContrastiveLoss, TripletLoss\n",
    "from metrics import AccumulatedAccuracyMetric\n",
    "\n",
    "# Step 2\n",
    "n_samples, n_features = siamese_train_dataset.train_data.shape\n",
    "embedding_net = EmbeddingNet(n_features, 2)\n",
    "# Step 3\n",
    "model = SiameseNet(embedding_net)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "# Step 4\n",
    "margin = 1.\n",
    "loss_fn = ContrastiveLoss(margin)\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 30\n",
    "# print training metrics every log_interval * batch_size\n",
    "log_interval = round(len(siamese_train_dataset)/4/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active CUDA Device: GPU 0\n",
      "Available devices  1\n",
      "Current cuda device  0\n"
     ]
    }
   ],
   "source": [
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/992 (0%)]\tLoss: 0.186778\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.48 GiB (GPU 0; 10.76 GiB total capacity; 9.62 GiB already allocated; 247.56 MiB free; 76.84 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-79b3554bd6ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m train_loss, val_loss = fit(siamese_train_loader, siamese_test_loader, model, loss_fn, optimizer, scheduler, \n\u001b[0;32m----> 2\u001b[0;31m     n_epochs, cuda, log_interval)\n\u001b[0m",
      "\u001b[0;32m~/github/metrx/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics, start_epoch)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Train stage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtrain_loss_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/metrx/trainer.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(train_loader, model, loss_fn, optimizer, cuda, log_interval, metrics)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.48 GiB (GPU 0; 10.76 GiB total capacity; 9.62 GiB already allocated; 247.56 MiB free; 76.84 MiB cached)"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = fit(siamese_train_loader, siamese_test_loader, model, loss_fn, optimizer, scheduler, \n",
    "    n_epochs, cuda, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0, n_epochs), train_loss, 'rx-', label='train')\n",
    "plt.plot(range(0, n_epochs), val_loss, 'bx-', label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def extract_embeddings(samples, target, model):\n",
    "    cuda = torch.cuda.is_available()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        assert len(samples) == len(target)\n",
    "        embeddings = np.zeros((len(samples), 2))\n",
    "        labels = np.zeros(len(target))\n",
    "        k = 0\n",
    "        if cuda:\n",
    "            samples = samples.cuda()\n",
    "        if isinstance(model, torch.nn.DataParallel):\n",
    "            embeddings[k:k+len(samples)] = model.module.get_embedding(samples).data.cpu().numpy()\n",
    "        else:\n",
    "            embeddings[k:k+len(samples)] = model.get_embedding(samples).data.cpu().numpy()\n",
    "        labels[k:k+len(samples)] = target\n",
    "        k += len(samples)\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_cl, train_labels_cl = extract_embeddings(siamese_train_dataset.train_data, siamese_train_dataset.labels, model)\n",
    "vis.sns_plot_embeddings(train_embeddings_cl, train_labels_cl, exp.labels_dict, \n",
    "                        hue='meta', style='Sample Type', alpha=0.5)\n",
    "plt.title('PanCancer Train: Siamese')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings_baseline, val_labels_baseline = extract_embeddings(siamese_test_dataset.test_data, siamese_test_dataset.labels, model)\n",
    "vis.sns_plot_embeddings(val_embeddings_baseline, val_labels_baseline, exp.labels_dict, \n",
    "                        hue='meta', style='Sample Type', alpha=0.5)\n",
    "plt.title('PanCancer Test: Siamese')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
