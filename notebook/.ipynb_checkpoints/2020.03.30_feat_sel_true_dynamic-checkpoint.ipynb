{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import datetime\n",
    "import pathlib\n",
    "\n",
    "from collections import OrderedDict \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Custom\n",
    "from dutils import Experiment\n",
    "from trainer import fit\n",
    "import visualization as vis\n",
    "from tcga_datasets import SiameseDataset\n",
    "\n",
    "# Models\n",
    "from tcga_networks import EmbeddingNet, SiameseNet\n",
    "from losses import ContrastiveLoss\n",
    "\n",
    "# Metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ANMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTCGA(disease):\n",
    "    path = \"/srv/nas/mk2/projects/pan-cancer/TCGA_CCLE_GCP/TCGA/TCGA_{}_counts.tsv.gz\"\n",
    "    files = [path.format(d) for d in disease]\n",
    "    return files\n",
    "\n",
    "\n",
    "def readGCP(files, biotype='protein_coding', mean=True):\n",
    "    \"\"\"\n",
    "    Paths to count matrices.\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    for f in files:\n",
    "        key = os.path.basename(f).split(\"_\")[1]\n",
    "        data = pd.read_csv(f, sep='\\t', index_col=0)\n",
    "        # transcript metadata\n",
    "        meta = pd.DataFrame([row[:-1] for row in data.index.str.split(\"|\")],\n",
    "                            columns=['ENST', 'ENSG', 'OTTHUMG', 'OTTHUMT', 'GENE-NUM', 'GENE', 'BP', 'BIOTYPE'])\n",
    "        meta = pd.MultiIndex.from_frame(meta)\n",
    "        data.index = meta\n",
    "        # subset transcripts\n",
    "        data = data.xs(key=biotype, level='BIOTYPE')\n",
    "        data = data.droplevel(['ENST', 'ENSG', 'OTTHUMG', 'OTTHUMT', 'GENE-NUM', 'BP'])\n",
    "        # average gene expression of splice variants\n",
    "        data = data.T\n",
    "        if mean:\n",
    "            data = data.groupby(by=data.columns, axis=1).mean()\n",
    "        data_dict[key] = data\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def uq_norm(df, q=0.75):\n",
    "    \"\"\"\n",
    "    Upper quartile normalization of GEX for samples.\n",
    "    \"\"\"\n",
    "    quantiles = df.quantile(q=q, axis=1)\n",
    "    norm = df.divide(quantiles, axis=0)\n",
    "    return norm\n",
    "\n",
    "\n",
    "def process_TCGA(disease=['BRCA', 'LUAD', 'KIRC', 'THCA', 'PRAD', 'SKCM']):\n",
    "    base=\"/srv/nas/mk2/projects/pan-cancer/TCGA_CCLE_GCP\"\n",
    "    # get files\n",
    "    tcga_files = getTCGA(disease)\n",
    "    # read meta/data\n",
    "    tcga_meta = pd.read_csv(os.path.join(base, \"TCGA/TCGA_GDC_ID_MAP.tsv\"), sep=\"\\t\")\n",
    "    tcga_raw = readGCP(tcga_files, mean=True)\n",
    "    # combine samples\n",
    "    tcga_raw = pd.concat(tcga_raw.values())\n",
    "    # Upper quartile normalization\n",
    "    tcga_raw = uq_norm(tcga_raw)\n",
    "    # log norm\n",
    "    tcga = tcga_raw.transform(np.log1p)\n",
    "    return tcga, tcga_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fsets(data, n_features, steps=5):\n",
    "    r = np.linspace(start=1, stop=n_features, num=steps, dtype='int')\n",
    "    idx = [np.random.choice(data.shape[1], size=i, replace=False) for i in r]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_training(train_data, train_labels, test_data, test_labels, feature_idx, embedding, exp_dir, cuda=True):\n",
    "    # Meta data\n",
    "    meta_data = {\"n_features\":[],\n",
    "                 \"model\":[],\n",
    "                 \"ANMI\":[]}\n",
    "    # Params\n",
    "    batch_size = 8\n",
    "    kwargs = {'num_workers': 10, 'pin_memory': True} if cuda else {'num_workers': 10}\n",
    "    \n",
    "    # Feature Index\n",
    "    for batch, feat in enumerate(feature_idx):\n",
    "        print(\"Number features: {}\\n\".format(len(feat)))\n",
    "        exp_data = {'feature_idx':feat}\n",
    "        # Define data\n",
    "        siamese_train_dataset = SiameseDataset(data=train_data.iloc[:,feat],\n",
    "                                           labels=train_labels,\n",
    "                                           train=True)\n",
    "        siamese_test_dataset = SiameseDataset(data=test_data.iloc[:,feat],\n",
    "                                          labels=test_labels,\n",
    "                                          train=False)\n",
    "        # Loaders\n",
    "        siamese_train_loader = torch.utils.data.DataLoader(siamese_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "        siamese_test_loader = torch.utils.data.DataLoader(siamese_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "        # Instantiate model\n",
    "        n_samples, n_features = siamese_train_dataset.train_data.shape\n",
    "        for i in range(3):\n",
    "            nmodel = 'model_{}'.format(i)\n",
    "            print(\"\\t{}\".format(nmodel))\n",
    "            embedding_net = EmbeddingNet(n_features, embedding)\n",
    "            model = SiameseNet(embedding_net)\n",
    "            if cuda:\n",
    "                model.cuda()\n",
    "            # Parameters\n",
    "            margin = 1.\n",
    "            loss_fn = ContrastiveLoss(margin)\n",
    "            lr = 1e-3\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "            n_epochs = 10\n",
    "            log_interval = round(len(siamese_train_dataset)/1/batch_size)\n",
    "            # Train\n",
    "            train_loss, val_loss = fit(siamese_train_loader, siamese_test_loader, model, loss_fn, optimizer, scheduler, \n",
    "                                       n_epochs, cuda, log_interval)\n",
    "            # Test Embeddings\n",
    "            val_embeddings_baseline, val_labels_baseline = vis.extract_embeddings(siamese_test_dataset.test_data, siamese_test_dataset.labels, model)\n",
    "            # Evaluation\n",
    "            n_clusters = len(np.unique(test_labels))\n",
    "            kmeans = KMeans(n_clusters=n_clusters)\n",
    "            siamese_clusters = kmeans.fit_predict(val_embeddings_baseline)\n",
    "            anmi = ANMI(siamese_clusters, val_labels_baseline)\n",
    "            # Store\n",
    "            meta_data['n_features'].append(len(feat))\n",
    "            meta_data['model'].append(nmodel)\n",
    "            meta_data['ANMI'].append(anmi)\n",
    "            exp_data[nmodel] = {'data': (val_embeddings_baseline, val_labels_baseline),\n",
    "                                'loss': (train_loss, val_loss),\n",
    "                                'ANMI': anmi}\n",
    "        pd.to_pickle(exp_data, os.path.join(exp_dir, \"model_{}.pkl\".format(len(feat))))\n",
    "    pd.to_pickle(meta_data, os.path.join(exp_dir, \"model_meta_data.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(disease, sample_type, **kwargs):\n",
    "    # GPUs\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = kwargs['device']\n",
    "    cuda = torch.cuda.is_available()\n",
    "    print(\"Cuda is available: {}\".format(cuda))\n",
    "    \n",
    "    # Read / write / process\n",
    "    tcga, tcga_meta = process_TCGA(disease)\n",
    "    # Feature design\n",
    "    feature_idx = generate_fsets(tcga, n_features=kwargs['n_features'], steps=kwargs['steps'])\n",
    "    # Experiment design\n",
    "    hierarchy = OrderedDict({'Disease':disease,\n",
    "                             'Sample Type':sample_type})\n",
    "    # Define experiment\n",
    "    exp = Experiment(meta_data=tcga_meta,\n",
    "                     hierarchy=hierarchy,\n",
    "                     index='CGHubAnalysisID',\n",
    "                     cases='Case ID',\n",
    "                     min_samples=20)\n",
    "    # Train / Test split\n",
    "    exp.train_test_split(cases='Case ID')\n",
    "    # Return data \n",
    "    train_data, train_labels = exp.get_data(tcga, subset=\"train\", dtype=np.float32)\n",
    "    test_data, test_labels = exp.get_data(tcga, subset=\"test\", dtype=np.float32)\n",
    "    \n",
    "    # Path *fix*\n",
    "    dtime = datetime.datetime.today().strftime(\"%Y.%m.%d_%H:%M\")\n",
    "    exp_dir = \"/srv/nas/mk2/projects/pan-cancer/experiments/feature_sel/{}_{}_{}_{}_{}-{}\".format(dtime,\n",
    "                                                                                                  kwargs['note'],\n",
    "                                                                                                  len(exp.labels_dict),\n",
    "                                                                                                  kwargs['embedding'],\n",
    "                                                                                                  kwargs['n_features'], \n",
    "                                                                                                  kwargs['steps'])\n",
    "    pathlib.Path(exp_dir).mkdir(parents=True, exist_ok=False)\n",
    "    print('Saving to: \\n{}'.format(exp_dir))\n",
    "    \n",
    "    # Meta data\n",
    "    experiments = {'experiment': exp,\n",
    "                   'train':(train_data, train_labels),\n",
    "                   'test': (test_data, test_labels)}\n",
    "    pd.to_pickle(experiments, os.path.join(exp_dir, \"experiment_meta_data.pkl\"))\n",
    "    \n",
    "    # Training\n",
    "    feature_training(train_data, train_labels, test_data, test_labels, feature_idx, kwargs['embedding'], exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BRCA',\n",
       " 'KIRC',\n",
       " 'LUAD',\n",
       " 'THCA',\n",
       " 'PRAD',\n",
       " 'LIHC',\n",
       " 'LUSC',\n",
       " 'HNSC',\n",
       " 'COAD',\n",
       " 'UCEC',\n",
       " 'STAD',\n",
       " 'KIRP',\n",
       " 'KICH']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base=\"/srv/nas/mk2/projects/pan-cancer/TCGA_CCLE_GCP\"\n",
    "# read meta/data\n",
    "tcga_meta = pd.read_csv(os.path.join(base, \"TCGA/TCGA_GDC_ID_MAP.tsv\"), sep=\"\\t\")\n",
    "# select disease\n",
    "disease = tcga_meta[tcga_meta['Sample Type']=='Solid Tissue Normal']['Disease'].value_counts()\n",
    "disease = list(disease[disease>=20].index)\n",
    "disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_type = ['Primary Tumor', 'Solid Tissue Normal']\n",
    "params = {\"device\":\"6\",\n",
    "          \"note\":\"true\",\n",
    "          \"n_features\":150,\n",
    "          \"steps\":50,\n",
    "          \"embedding\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available: True\n",
      "Saving to: \n",
      "/srv/nas/mk2/projects/pan-cancer/experiments/feature_sel/2020.03.30_09:13_true_26_2_150-50\n",
      "Number features: 1\n",
      "\n",
      "\tmodel_0\n",
      "Train: [0/5622 (0%)]\tLoss: 0.248370\n",
      "Epoch: 1/10. Train set: Average loss: 0.1629\n",
      "Epoch: 1/10. Validation set: Average loss: 0.1611\n",
      "Train: [0/5622 (0%)]\tLoss: 0.164451\n",
      "Epoch: 2/10. Train set: Average loss: 0.1567\n",
      "Epoch: 2/10. Validation set: Average loss: 0.1464\n",
      "Train: [0/5622 (0%)]\tLoss: 0.188929\n",
      "Epoch: 3/10. Train set: Average loss: 0.1464\n",
      "Epoch: 3/10. Validation set: Average loss: 0.1754\n",
      "Train: [0/5622 (0%)]\tLoss: 0.203978\n"
     ]
    }
   ],
   "source": [
    "main(disease=disease, sample_type=sample_type, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
