{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(123)\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# notebook settings\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File ID</th>\n",
       "      <th>File Name</th>\n",
       "      <th>Data Category</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Project ID</th>\n",
       "      <th>Case ID</th>\n",
       "      <th>Sample ID</th>\n",
       "      <th>Sample Type</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>754774dd-77e1-4cf5-b9b5-3afad9f41410</td>\n",
       "      <td>999edb9e-8a45-4115-84d5-fca75dcfa639.FPKM.txt.gz</td>\n",
       "      <td>Transcriptome Profiling</td>\n",
       "      <td>Gene Expression Quantification</td>\n",
       "      <td>TCGA-BRCA</td>\n",
       "      <td>TCGA-E2-A1IG</td>\n",
       "      <td>TCGA-E2-A1IG-01A</td>\n",
       "      <td>Primary Tumor</td>\n",
       "      <td>FPKM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8bf102b9-baf7-4749-bcd0-eca25f600722</td>\n",
       "      <td>23393a6a-bfbc-4dec-9ab5-e78a487a095f.FPKM.txt.gz</td>\n",
       "      <td>Transcriptome Profiling</td>\n",
       "      <td>Gene Expression Quantification</td>\n",
       "      <td>TCGA-BRCA</td>\n",
       "      <td>TCGA-EW-A1J5</td>\n",
       "      <td>TCGA-EW-A1J5-01A</td>\n",
       "      <td>Primary Tumor</td>\n",
       "      <td>FPKM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5bf7609e-68cb-4ddb-8f05-ee1d4f92cf9b</td>\n",
       "      <td>4a9bb3fd-4e75-4585-82f7-7254889b9838.FPKM.txt.gz</td>\n",
       "      <td>Transcriptome Profiling</td>\n",
       "      <td>Gene Expression Quantification</td>\n",
       "      <td>TCGA-BRCA</td>\n",
       "      <td>TCGA-AR-A1AU</td>\n",
       "      <td>TCGA-AR-A1AU-01A</td>\n",
       "      <td>Primary Tumor</td>\n",
       "      <td>FPKM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10a40ceb-080c-4758-97f9-1a262e2639ed</td>\n",
       "      <td>9858d286-1b96-4414-bd09-d73dc6f1c79e.FPKM.txt.gz</td>\n",
       "      <td>Transcriptome Profiling</td>\n",
       "      <td>Gene Expression Quantification</td>\n",
       "      <td>TCGA-LGG</td>\n",
       "      <td>TCGA-DB-A64R</td>\n",
       "      <td>TCGA-DB-A64R-01A</td>\n",
       "      <td>Primary Tumor</td>\n",
       "      <td>FPKM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2600ef39-0bdf-4e10-9fdf-e3dbed7b5383</td>\n",
       "      <td>f7182de7-067e-467b-af88-790ad3e63eec.FPKM.txt.gz</td>\n",
       "      <td>Transcriptome Profiling</td>\n",
       "      <td>Gene Expression Quantification</td>\n",
       "      <td>TCGA-LGG</td>\n",
       "      <td>TCGA-P5-A77X</td>\n",
       "      <td>TCGA-P5-A77X-01A</td>\n",
       "      <td>Primary Tumor</td>\n",
       "      <td>FPKM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                File ID  \\\n",
       "0  754774dd-77e1-4cf5-b9b5-3afad9f41410   \n",
       "1  8bf102b9-baf7-4749-bcd0-eca25f600722   \n",
       "2  5bf7609e-68cb-4ddb-8f05-ee1d4f92cf9b   \n",
       "3  10a40ceb-080c-4758-97f9-1a262e2639ed   \n",
       "4  2600ef39-0bdf-4e10-9fdf-e3dbed7b5383   \n",
       "\n",
       "                                          File Name            Data Category  \\\n",
       "0  999edb9e-8a45-4115-84d5-fca75dcfa639.FPKM.txt.gz  Transcriptome Profiling   \n",
       "1  23393a6a-bfbc-4dec-9ab5-e78a487a095f.FPKM.txt.gz  Transcriptome Profiling   \n",
       "2  4a9bb3fd-4e75-4585-82f7-7254889b9838.FPKM.txt.gz  Transcriptome Profiling   \n",
       "3  9858d286-1b96-4414-bd09-d73dc6f1c79e.FPKM.txt.gz  Transcriptome Profiling   \n",
       "4  f7182de7-067e-467b-af88-790ad3e63eec.FPKM.txt.gz  Transcriptome Profiling   \n",
       "\n",
       "                        Data Type Project ID       Case ID         Sample ID  \\\n",
       "0  Gene Expression Quantification  TCGA-BRCA  TCGA-E2-A1IG  TCGA-E2-A1IG-01A   \n",
       "1  Gene Expression Quantification  TCGA-BRCA  TCGA-EW-A1J5  TCGA-EW-A1J5-01A   \n",
       "2  Gene Expression Quantification  TCGA-BRCA  TCGA-AR-A1AU  TCGA-AR-A1AU-01A   \n",
       "3  Gene Expression Quantification   TCGA-LGG  TCGA-DB-A64R  TCGA-DB-A64R-01A   \n",
       "4  Gene Expression Quantification   TCGA-LGG  TCGA-P5-A77X  TCGA-P5-A77X-01A   \n",
       "\n",
       "     Sample Type  data  \n",
       "0  Primary Tumor  FPKM  \n",
       "1  Primary Tumor  FPKM  \n",
       "2  Primary Tumor  FPKM  \n",
       "3  Primary Tumor  FPKM  \n",
       "4  Primary Tumor  FPKM  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = pd.read_csv('../data/TCGA/rna-seq_pan/meta/gdc_sample_sheet.2019-12-12.tsv', sep=\"\\t\")\n",
    "# get file type\n",
    "samples['data'] = [val[1] for i,val in samples['File Name'].str.split(\".\").items()]\n",
    "samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples with RNAseq adjacent normal tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FPKM    636\n",
       "Name: data, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[samples['Sample Type']=='Solid Tissue Normal']['data'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRCA    1206\n",
       "LUAD     588\n",
       "UCEC     567\n",
       "KIRC     554\n",
       "LUSC     543\n",
       "LGG      524\n",
       "PRAD     517\n",
       "COAD     506\n",
       "THCA     505\n",
       "SKCM     469\n",
       "BLCA     431\n",
       "LIHC     421\n",
       "STAD     402\n",
       "OV       379\n",
       "KIRP     308\n",
       "CESC     306\n",
       "PAAD     171\n",
       "ESCA     171\n",
       "GBM      166\n",
       "TGCT     150\n",
       "PCPG     133\n",
       "LAML     123\n",
       "KICH      81\n",
       "ACC       75\n",
       "CHOL      41\n",
       "SARC      10\n",
       "DLBC       9\n",
       "READ       7\n",
       "MESO       1\n",
       "Name: project, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['project'] = [val[1] for i,val in samples['Project ID'].str.split(\"-\").items()]\n",
    "samples['project'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all cases with adjacent normal tissue\n",
    "cases = samples[samples['Sample Type']=='Solid Tissue Normal']['Case ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# disparity in cases\n",
    "samples[(samples['Case ID'].isin(cases)) & (samples['Sample Type']=='Primary Tumor') \n",
    "        & (samples['data']=='FPKM') & (samples['project']=='BRCA')]['Case ID'].nunique()\n",
    "samples[(samples['Case ID'].isin(cases)) & (samples['Sample Type']=='Solid Tissue Normal') \n",
    "        & (samples['data']=='FPKM') & (samples['project']=='BRCA')]['Case ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide, join, subset\n",
    "case_tumor = samples[(samples['Case ID'].isin(cases)) & (samples['Sample Type']=='Primary Tumor') & \n",
    "                     (samples['data']=='FPKM') & (samples['project']=='BRCA')]\n",
    "case_norm = samples[(samples['Case ID'].isin(cases)) & (samples['Sample Type']=='Solid Tissue Normal') & \n",
    "                    (samples['data']=='FPKM') & (samples['project']=='BRCA')]\n",
    "cases = case_norm[case_norm['Case ID'].isin(case_tumor['Case ID'])]['Case ID']\n",
    "cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_tumor = case_tumor[case_tumor['Case ID'].isin(cases)]\n",
    "case_norm = case_norm[case_norm['Case ID'].isin(cases)]\n",
    "cases = pd.concat([case_tumor, case_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(111, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(227, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_tumor.shape\n",
    "case_norm.shape\n",
    "cases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Primary Tumor          90\n",
       "Solid Tissue Normal    80\n",
       "Name: Sample Type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Solid Tissue Normal    31\n",
       "Primary Tumor          26\n",
       "Name: Sample Type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = 'Sample Type'\n",
    "cases[target] = cases[target].astype('category')\n",
    "\n",
    "train, test = train_test_split(cases)\n",
    "train[target].value_counts()\n",
    "test[target].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Primary Tumor', 'Solid Tissue Normal'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[target].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7ca82ae830>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Primary Tumor': 0, 'Solid Tissue Normal': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "torch.manual_seed(123)\n",
    "\n",
    "from trainer import fit\n",
    "import visualization as vis\n",
    "import numpy as np\n",
    "cuda = torch.cuda.is_available()\n",
    "print(\"Cuda is available: {}\".format(cuda))\n",
    "\n",
    "classes = {key:val for val,key in enumerate(train[target].cat.categories.values)}\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcga_datasets import TCGA, SiameseTCGA\n",
    "root_dir = \"../data/TCGA/rna-seq_pan/\"\n",
    "batch_size = 1\n",
    "\n",
    "train_dataset = TCGA(root_dir, samples=train, train=True, target=target)\n",
    "test_dataset = TCGA(root_dir, samples=test, train=False, target=target)\n",
    "\n",
    "kwargs = {'num_workers': 10, 'pin_memory': True} if cuda else {'num_workers': 10}\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseNet(\n",
       "  (embedding_net): EmbeddingNet(\n",
       "    (fc): Sequential(\n",
       "      (linear1): Linear(in_features=60483, out_features=2000, bias=True)\n",
       "      (relu1): PReLU(num_parameters=1)\n",
       "      (linear2): Linear(in_features=2000, out_features=500, bias=True)\n",
       "      (relu2): PReLU(num_parameters=1)\n",
       "      (linear3): Linear(in_features=500, out_features=250, bias=True)\n",
       "      (relu3): PReLU(num_parameters=1)\n",
       "      (linear4): Linear(in_features=250, out_features=100, bias=True)\n",
       "      (relu4): PReLU(num_parameters=1)\n",
       "      (linear5): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (relu5): PReLU(num_parameters=1)\n",
       "      (linear6): Linear(in_features=50, out_features=10, bias=True)\n",
       "      (relu6): PReLU(num_parameters=1)\n",
       "      (linear7): Linear(in_features=10, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 set up dataloader\n",
    "root_dir = \"../data/TCGA\"\n",
    "siamese_train_dataset = SiameseTCGA(train_dataset) # Returns pairs of images and target same/different\n",
    "siamese_test_dataset = SiameseTCGA(test_dataset)\n",
    "batch_size = 8\n",
    "kwargs = {'num_workers': 10, 'pin_memory': True} if cuda else {}\n",
    "siamese_train_loader = torch.utils.data.DataLoader(siamese_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "siamese_test_loader = torch.utils.data.DataLoader(siamese_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "# Set up the network and training parameters\n",
    "from tcga_networks import EmbeddingNet, SiameseNet\n",
    "from losses import ContrastiveLoss\n",
    "from metrics import AccumulatedAccuracyMetric\n",
    "\n",
    "# Step 2\n",
    "embedding_net = EmbeddingNet()\n",
    "# Step 3\n",
    "model = SiameseNet(embedding_net)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "# Step 4\n",
    "margin = 1.\n",
    "loss_fn = ContrastiveLoss(margin)\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 30\n",
    "# print training metrics every log_interval * batch_size\n",
    "log_interval = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/170 (0%)]\tLoss: 0.268963\n",
      "Epoch: 1/30. Train set: Average loss: 109.3384\n",
      "Epoch: 1/30. Validation set: Average loss: 19.4182\n",
      "Train: [0/170 (0%)]\tLoss: 309.796631\n",
      "Epoch: 2/30. Train set: Average loss: 128.6826\n",
      "Epoch: 2/30. Validation set: Average loss: 146.4794\n",
      "Train: [0/170 (0%)]\tLoss: 120.472649\n",
      "Epoch: 3/30. Train set: Average loss: 220.2393\n",
      "Epoch: 3/30. Validation set: Average loss: 7.1959\n",
      "Train: [0/170 (0%)]\tLoss: 1.989862\n",
      "Epoch: 4/30. Train set: Average loss: 13.7897\n",
      "Epoch: 4/30. Validation set: Average loss: 0.8082\n",
      "Train: [0/170 (0%)]\tLoss: 3.589590\n",
      "Epoch: 5/30. Train set: Average loss: 3.9411\n",
      "Epoch: 5/30. Validation set: Average loss: 5.1269\n",
      "Train: [0/170 (0%)]\tLoss: 0.450236\n",
      "Epoch: 6/30. Train set: Average loss: 8.6736\n",
      "Epoch: 6/30. Validation set: Average loss: 0.8676\n",
      "Train: [0/170 (0%)]\tLoss: 0.245182\n",
      "Epoch: 7/30. Train set: Average loss: 1.4281\n",
      "Epoch: 7/30. Validation set: Average loss: 0.2053\n",
      "Train: [0/170 (0%)]\tLoss: 0.009832\n",
      "Epoch: 8/30. Train set: Average loss: 0.6234\n",
      "Epoch: 8/30. Validation set: Average loss: 0.1697\n",
      "Train: [0/170 (0%)]\tLoss: 0.110812\n",
      "Epoch: 9/30. Train set: Average loss: 0.1303\n",
      "Epoch: 9/30. Validation set: Average loss: 0.1713\n",
      "Train: [0/170 (0%)]\tLoss: 0.057411\n",
      "Epoch: 10/30. Train set: Average loss: 0.1504\n",
      "Epoch: 10/30. Validation set: Average loss: 0.1757\n",
      "Train: [0/170 (0%)]\tLoss: 0.088315\n",
      "Epoch: 11/30. Train set: Average loss: 0.1730\n",
      "Epoch: 11/30. Validation set: Average loss: 0.1771\n",
      "Train: [0/170 (0%)]\tLoss: 0.047901\n",
      "Epoch: 12/30. Train set: Average loss: 0.1277\n",
      "Epoch: 12/30. Validation set: Average loss: 0.1753\n",
      "Train: [0/170 (0%)]\tLoss: 0.138502\n",
      "Epoch: 13/30. Train set: Average loss: 0.1459\n",
      "Epoch: 13/30. Validation set: Average loss: 0.1765\n",
      "Train: [0/170 (0%)]\tLoss: 0.175999\n",
      "Epoch: 14/30. Train set: Average loss: 0.1600\n",
      "Epoch: 14/30. Validation set: Average loss: 0.1764\n",
      "Train: [0/170 (0%)]\tLoss: 0.157627\n",
      "Epoch: 15/30. Train set: Average loss: 0.1315\n",
      "Epoch: 15/30. Validation set: Average loss: 0.1736\n",
      "Train: [0/170 (0%)]\tLoss: 0.058434\n",
      "Epoch: 16/30. Train set: Average loss: 0.1153\n",
      "Epoch: 16/30. Validation set: Average loss: 0.1741\n",
      "Train: [0/170 (0%)]\tLoss: 0.089683\n",
      "Epoch: 17/30. Train set: Average loss: 0.1084\n",
      "Epoch: 17/30. Validation set: Average loss: 0.1739\n",
      "Train: [0/170 (0%)]\tLoss: 0.037757\n",
      "Epoch: 18/30. Train set: Average loss: 0.1050\n",
      "Epoch: 18/30. Validation set: Average loss: 0.1737\n",
      "Train: [0/170 (0%)]\tLoss: 0.125616\n",
      "Epoch: 19/30. Train set: Average loss: 0.0914\n",
      "Epoch: 19/30. Validation set: Average loss: 0.1736\n",
      "Train: [0/170 (0%)]\tLoss: 0.240488\n",
      "Epoch: 20/30. Train set: Average loss: 0.1259\n",
      "Epoch: 20/30. Validation set: Average loss: 0.1733\n",
      "Train: [0/170 (0%)]\tLoss: 0.069203\n",
      "Epoch: 21/30. Train set: Average loss: 0.1018\n",
      "Epoch: 21/30. Validation set: Average loss: 0.1735\n",
      "Train: [0/170 (0%)]\tLoss: 0.223753\n",
      "Epoch: 22/30. Train set: Average loss: 0.1108\n",
      "Epoch: 22/30. Validation set: Average loss: 0.1737\n",
      "Train: [0/170 (0%)]\tLoss: 0.077433\n",
      "Epoch: 23/30. Train set: Average loss: 0.1132\n",
      "Epoch: 23/30. Validation set: Average loss: 0.1737\n",
      "Train: [0/170 (0%)]\tLoss: 0.048831\n",
      "Epoch: 24/30. Train set: Average loss: 0.1394\n",
      "Epoch: 24/30. Validation set: Average loss: 0.1730\n",
      "Train: [0/170 (0%)]\tLoss: 0.066329\n",
      "Epoch: 25/30. Train set: Average loss: 0.1402\n",
      "Epoch: 25/30. Validation set: Average loss: 0.1730\n",
      "Train: [0/170 (0%)]\tLoss: 0.042261\n",
      "Epoch: 26/30. Train set: Average loss: 0.1216\n",
      "Epoch: 26/30. Validation set: Average loss: 0.1730\n",
      "Train: [0/170 (0%)]\tLoss: 0.250866\n",
      "Epoch: 27/30. Train set: Average loss: 0.1322\n",
      "Epoch: 27/30. Validation set: Average loss: 0.1730\n",
      "Train: [0/170 (0%)]\tLoss: 0.017615\n",
      "Epoch: 28/30. Train set: Average loss: 0.1114\n",
      "Epoch: 28/30. Validation set: Average loss: 0.1730\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = fit(siamese_train_loader, siamese_test_loader, model, loss_fn, optimizer, scheduler, \n",
    "    n_epochs, cuda, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0, n_epochs), train_loss, 'rx-')\n",
    "plt.plot(range(0, n_epochs), val_loss, 'bx-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_cl, train_labels_cl = vis.extract_embeddings(train_loader, model)\n",
    "vis.plot_embeddings(train_embeddings_cl, train_labels_cl, classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings_baseline, val_labels_baseline = vis.extract_embeddings(test_loader, model)\n",
    "vis.plot_embeddings(val_embeddings_baseline, val_labels_baseline, classes.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from captum.attr import LayerActivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1, data2, label = tuple(siamese_test_dataset.test_pairs[-1])\n",
    "data1 = Variable(siamese_test_dataset.test_data[data1], requires_grad=True).cuda().view(1, -1)\n",
    "data2 = Variable(siamese_test_dataset.test_data[data2], requires_grad=True).cuda().view(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(tmp_model.get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.shape\n",
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr, delta = ig.attribute(data1,target=0, return_convergence_delta=True)\n",
    "attr = attr.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.Series(data=attr[0], index=train_dataset.data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes\n",
    "tumor_test_idx = siamese_test_dataset.label_to_indices[classes['Primary Tumor']]\n",
    "tumor_test = Variable(siamese_test_dataset.test_data[test_idx], requires_grad=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_test.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr, delta = ig.attribute(tumor_test ,target=0, return_convergence_delta=True)\n",
    "attr = attr.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr.shape\n",
    "feat_imp = pd.Series(data=attr.mean(axis=0), index=train_dataset.data.columns)\n",
    "feat_imp.hist(bins=100)\n",
    "feat_imp.describe()\n",
    "feat_imp.nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to get all tumor samples and rank avg feature attribution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
