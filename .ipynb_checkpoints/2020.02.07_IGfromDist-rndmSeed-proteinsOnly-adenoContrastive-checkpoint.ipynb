{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#np.random.seed(123)\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# notebook settings\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCGA-LUSC    301\n",
       "TCGA-LUAD    287\n",
       "CPTAC-3      209\n",
       "Name: Project ID, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = pd.read_csv('../data/TCGA/rna-seq_adeno/meta/gdc_sample_sheet.2020-01-27.tsv', sep=\"\\t\")\n",
    "# get file type\n",
    "samples['data'] = [val[1] for i,val in samples['File Name'].str.split(\".\").items()]\n",
    "samples['Project ID'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples with RNAseq adjacent normal tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Primary Tumor                               558\n",
       "Solid Tissue Normal                         206\n",
       "Primary Tumor, Primary Tumor                 29\n",
       "Solid Tissue Normal, Solid Tissue Normal      4\n",
       "Name: Sample Type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['Sample Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.loc[samples['Sample Type']=='Primary Tumor, Primary Tumor', 'Sample Type'] = 'Primary Tumor'\n",
    "samples.loc[samples['Sample Type']=='Solid Tissue Normal, Solid Tissue Normal', 'Sample Type'] = 'Solid Tissue Normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Primary Tumor          587\n",
       "Solid Tissue Normal    210\n",
       "Name: Sample Type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['Sample Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all cases with adjacent normal tissue\n",
    "cases = samples[samples['Sample Type']=='Solid Tissue Normal']['Case ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# disparity in cases\n",
    "samples[(samples['Case ID'].isin(cases)) & (samples['Sample Type']=='Primary Tumor') \n",
    "        & (samples['data']=='FPKM')]['Case ID'].nunique()\n",
    "samples[(samples['Case ID'].isin(cases)) & (samples['Sample Type']=='Solid Tissue Normal') \n",
    "        & (samples['data']=='FPKM')]['Case ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide, join, subset\n",
    "case_tumor = samples[(samples['Case ID'].isin(cases)) & (samples['Sample Type']=='Primary Tumor') & \n",
    "                     (samples['data']=='FPKM')]\n",
    "case_norm = samples[(samples['Case ID'].isin(cases)) & (samples['Sample Type']=='Solid Tissue Normal') & \n",
    "                    (samples['data']=='FPKM')]\n",
    "cases = pd.merge(case_tumor['Case ID'], case_norm['Case ID'])['Case ID']\n",
    "cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_tumor = case_tumor[case_tumor['Case ID'].isin(cases)]\n",
    "case_norm = case_norm[case_norm['Case ID'].isin(cases)]\n",
    "cases = pd.concat([case_tumor, case_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(176, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(363, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_tumor.shape\n",
    "case_norm.shape\n",
    "cases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Ensembl genes to Proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18842, 22)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_map = pd.read_csv(\"/srv/home/wconnell/keiser/data/uniprot_mapping_ids/map_ensembl_uniprot.csv\")\n",
    "reviewed_proteins = pd.read_csv(\"/srv/home/wconnell/keiser/data/uniprot_mapping_ids/TCGA_rnaseq_uniprot_features.tab.gz\", sep=\"\\t\")\n",
    "proteins = pd.merge(id_map, reviewed_proteins, left_on='UNIPROT_ID', right_on='Entry name')\n",
    "proteins['hgnc'] = [gene.split(\";\")[0] for gene in proteins['Gene names  (primary )']]\n",
    "proteins.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Primary Tumor          138\n",
       "Solid Tissue Normal    134\n",
       "Name: Sample Type, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Primary Tumor          49\n",
       "Solid Tissue Normal    42\n",
       "Name: Sample Type, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "target = 'Sample Type'\n",
    "cases[target] = cases[target].astype('category')\n",
    "\n",
    "train, test = train_test_split(cases)\n",
    "train[target].value_counts()\n",
    "test[target].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Primary Tumor': 0, 'Solid Tissue Normal': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "#torch.manual_seed(123)\n",
    "\n",
    "from trainer import fit\n",
    "import visualization as vis\n",
    "import numpy as np\n",
    "cuda = torch.cuda.is_available()\n",
    "print(\"Cuda is available: {}\".format(cuda))\n",
    "\n",
    "classes = {key:val for val,key in enumerate(train[target].cat.categories.values)}\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcga_datasets import TCGA, SiameseTCGA\n",
    "root_dir = \"../data/TCGA/rna-seq_adeno/\"\n",
    "batch_size = 1\n",
    "\n",
    "train_dataset = TCGA(root_dir, samples=train, train=True, target=target, log=True)\n",
    "test_dataset = TCGA(root_dir, samples=test, train=False, target=target, log=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_dataset.data = pd.DataFrame(scaler.fit_transform(train_dataset.data),\n",
    "                                  index=train_dataset.data.index,\n",
    "                                  columns=train_dataset.data.columns)\n",
    "test_dataset.data = pd.DataFrame(scaler.transform(test_dataset.data),\n",
    "                                 index=test_dataset.data.index,\n",
    "                                 columns=test_dataset.data.columns)\n",
    "\n",
    "kwargs = {'num_workers': 10, 'pin_memory': True} if cuda else {'num_workers': 10}\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset gene data to annotated proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(train_dataset.data.columns, test_dataset.data.columns)\n",
    "parsed_cols = [ens[0] for ens in train_dataset.data.columns.str.split(\".\")]\n",
    "\n",
    "train_dataset.data.columns, test_dataset.data.columns = parsed_cols, parsed_cols\n",
    "protein_overlap_idx = np.isin(train_dataset.data.columns, proteins['ENSEMBL_ID'].values)\n",
    "\n",
    "train_dataset.data = train_dataset.data.loc[:,protein_overlap_idx]\n",
    "test_dataset.data = test_dataset.data.loc[:,protein_overlap_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write out test set for DE analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(test_dataset.data, \"../data/tmp/test_dataset.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_cond = []\n",
    "for label in test_dataset.labels:\n",
    "    if label == test_dataset.labels_dict['Primary Tumor']:\n",
    "        map_cond.append('Primary Tumor')\n",
    "    elif label == test_dataset.labels_dict['Solid Tissue Normal']:\n",
    "        map_cond.append('Solid Tissue Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.DataFrame({'label':test_dataset.labels,\n",
    "                    'condition':map_cond},\n",
    "                    index=test_dataset.data.index)\n",
    "meta.to_pickle(\"../data/tmp/test_dataset_meta.pkl.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 set up dataloader\n",
    "root_dir = \"../data/TCGA\"\n",
    "siamese_train_dataset = SiameseTCGA(train_dataset) # Returns pairs of images and target same/different\n",
    "siamese_test_dataset = SiameseTCGA(test_dataset)\n",
    "batch_size = 8\n",
    "kwargs = {'num_workers': 10, 'pin_memory': True} if cuda else {}\n",
    "siamese_train_loader = torch.utils.data.DataLoader(siamese_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "siamese_test_loader = torch.utils.data.DataLoader(siamese_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "# Set up the network and training parameters\n",
    "from tcga_networks import EmbeddingNet, SiameseNet\n",
    "from losses import ContrastiveLoss\n",
    "from metrics import AccumulatedAccuracyMetric\n",
    "\n",
    "# Step 2\n",
    "n_samples, n_features = siamese_train_dataset.data.shape\n",
    "embedding_net = EmbeddingNet(n_features)\n",
    "# Step 3\n",
    "model = SiameseNet(embedding_net)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "# Step 4\n",
    "margin = 1.\n",
    "loss_fn = ContrastiveLoss(margin)\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 10\n",
    "# print training metrics every log_interval * batch_size\n",
    "log_interval = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, val_loss = fit(siamese_train_loader, siamese_test_loader, model, loss_fn, optimizer, scheduler, \n",
    "    n_epochs, cuda, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0, n_epochs), train_loss, 'rx-')\n",
    "plt.plot(range(0, n_epochs), val_loss, 'bx-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_cl, train_labels_cl = vis.extract_embeddings(train_loader, model)\n",
    "vis.plot_embeddings(train_embeddings_cl, train_labels_cl, siamese_train_dataset.labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings_baseline, val_labels_baseline = vis.extract_embeddings(test_loader, model)\n",
    "vis.plot_embeddings(val_embeddings_baseline, val_labels_baseline, siamese_test_dataset.labels_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients\n",
    "Test completeness axiom through comparison of different baselines\n",
    "\n",
    "\"Integrated gradients satisfy an\n",
    "axiom called completeness that the attributions add up to\n",
    "the difference between the output of F at the input x and\n",
    "the baseline x'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from captum.attr import LayerActivation\n",
    "from captum.attr import IntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribution_pairs(SiameseTCGA, exp, ctrl):\n",
    "    # subset different samples\n",
    "    negative_pairs = np.array(SiameseTCGA.test_pairs)\n",
    "    negative_pairs = negative_pairs[negative_pairs[:,2] == 0]\n",
    "    # map labels to integers\n",
    "    ctrl = siamese_test_dataset.labels_dict[ctrl]\n",
    "    exp = siamese_test_dataset.labels_dict[exp]\n",
    "    # ordered indices of samples\n",
    "    ctrl_data = [idx for pair in negative_pairs[:, :2] for idx in pair if np.isin(idx, SiameseTCGA.label_to_indices[ctrl])]\n",
    "    exp_data = [idx for pair in negative_pairs[:, :2] for idx in pair if np.isin(idx, SiameseTCGA.label_to_indices[exp])]\n",
    "    # data\n",
    "    ctrl_data = Variable(SiameseTCGA.test_data[ctrl_data], requires_grad=True)\n",
    "    exp_data = Variable(SiameseTCGA.test_data[exp_data], requires_grad=True)\n",
    "    return ctrl_data, exp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IG with Control vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_data, exp_data = attribution_pairs(siamese_test_dataset, exp='Primary Tumor', ctrl='Solid Tissue Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import PairwiseDistance\n",
    "pdist = PairwiseDistance(p=2)\n",
    "pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(model.get_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Healthy as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr, delta = ig.attribute(exp_data.cuda(), ctrl_data.cuda(), target=None, n_steps=50, return_convergence_delta=True,\n",
    "                          additional_forward_args=(ctrl_data.cuda(), pdist))\n",
    "attr = attr.cpu().detach().numpy()\n",
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame(data=attr.mean(axis=0), index=train_dataset.data.columns, columns=['Attribution'])\n",
    "feat_imp.shape\n",
    "feat_imp.describe()\n",
    "feat_imp.nlargest(10, columns='Attribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protein Feature Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins['ENSEMBL_ID'].values.shape\n",
    "attr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame(data=attr.mean(axis=0), index=train_dataset.data.columns, columns=['Attribution'])\n",
    "feat_imp.shape\n",
    "feat_imp = pd.merge(feat_imp, proteins.drop_duplicates(subset='ENSEMBL_ID'), left_index=True, right_on='ENSEMBL_ID', how='left').sort_values(by='Attribution', ascending=False).reset_index(drop=True)\n",
    "feat_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp.to_pickle(\"../data/tmp/attr_avg.pkl.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now go to /srv/home/wconnell/github/diffxpy/notebook/2020.02.05_test_DE_analysis and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp[['Attribution', 'hgnc', 'Protein names', 'Gene ontology (biological process)', 'Gene ontology (molecular function)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
